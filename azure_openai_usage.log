HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
Retrying request to /chat/completions in 0.816083 seconds
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
Retrying request to /chat/completions in 0.754662 seconds
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
Retrying request to /chat/completions in 1.509179 seconds
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}})
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
Retrying request to /chat/completions in 0.852425 seconds
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
Retrying request to /chat/completions in 1.544049 seconds
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}})
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
Retrying request to /chat/completions in 0.941040 seconds
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
Retrying request to /chat/completions in 1.715688 seconds
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 0.5s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 57330 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 1.7s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 57330 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 1.3s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 57330 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 4.9s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 57330 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 9.2s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 57330 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 27.9s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 57330 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 63.4s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 57330 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 88.9s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 57330 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 0.3s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 57377 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 1.7s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 57377 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 2.1s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 57377 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 1.2s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 57377 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 12.3s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 57377 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 25.8s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 57377 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 38.5s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 57377 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 28.2s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 57377 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 186.5s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 57377 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 239.7s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 57377 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 411.2s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 57377 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
Retrying request to /chat/completions in 0.782801 seconds
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 0.6s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 57360 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 1.7s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 57360 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 3.5s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 57360 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 1.4s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 57360 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 14.3s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 57360 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 13.0s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 57360 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 47.5s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 57360 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 35.3s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 57360 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 108.4s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 57360 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 0.8s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 19749 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 0.1s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 19749 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 4.0s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 19749 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 7.6s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 19749 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 7.3s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 19749 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 19.4s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 19749 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 0.3s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 20208 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 1.2s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 20208 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 2.8s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 20208 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 3.5s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 20208 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 0.7s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 20208 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 15.1s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 20208 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 0.1s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 19979 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 1.8s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 19979 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 0.3s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 19290 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 1.0s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 19290 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 0.2s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 13736 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 1.4s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 13736 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 400 model_error"
Backing off request(...) for 4.0s (openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, your messages resulted in 13736 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
Retrying request to /chat/completions in 0.782953 seconds
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
HTTP Request: POST https://bxaisc.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15 "HTTP/1.1 200 OK"
